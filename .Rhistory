library(phyloseq)
# Load the RDA file
load("data/BCM_16S_wheat_phyloseq_filtered_lulu.rda")
# Extract OTU data from wheat phyloseq RDA file
# Load required libraries
library(phyloseq)
setwd("c:/MicrobiomeBot/Microbot-")
# Load the RDA file
load("data/BCM_16S_wheat_phyloseq_filtered_lulu.rda")
# Check what objects are loaded
print("Objects loaded from RDA file:")
print(ls())
# Assuming the phyloseq object is named something like 'ps', 'phyloseq_obj', or similar
# Let's check all objects and find the phyloseq one
for(obj_name in ls()) {
obj <- get(obj_name)
if(class(obj)[1] == "phyloseq") {
cat("Found phyloseq object:", obj_name, "\n")
ps <- obj
break
}
}
# If phyloseq object found, extract data
if(exists("ps")) {
# Extract OTU table (abundance data)
otu_table_data <- as.data.frame(otu_table(ps))
# Extract taxonomy table (species names)
if(!is.null(tax_table(ps))) {
taxonomy_data <- as.data.frame(tax_table(ps))
# Create species names from taxonomy
# Use the lowest available taxonomic level
species_names <- apply(taxonomy_data, 1, function(x) {
# Find the last non-NA taxonomic level
last_level <- tail(x[!is.na(x) & x != ""], 1)
if(length(last_level) > 0) {
return(as.character(last_level))
} else {
return(rownames(taxonomy_data)[which(apply(taxonomy_data, 1, function(y) identical(y, x)))])
}
})
# Add species names as row names to OTU table
rownames(otu_table_data) <- species_names
# Save taxonomy information
write.csv(taxonomy_data, "taxonomy_table.csv", row.names = TRUE)
cat("Taxonomy table saved to taxonomy_table.csv\n")
}
# Save OTU table with species names
write.csv(otu_table_data, "otu_table_with_species.csv", row.names = TRUE)
# Also save a version with numeric IDs (for compatibility with current analysis)
otu_numeric <- otu_table_data
rownames(otu_numeric) <- 0:(nrow(otu_numeric)-1)
write.csv(otu_numeric, "otu_table_numeric.csv", row.names = TRUE)
# Create a mapping file between numeric IDs and species names
if(exists("species_names")) {
species_mapping <- data.frame(
numeric_id = 0:(length(species_names)-1),
species_name = species_names,
stringsAsFactors = FALSE
)
write.csv(species_mapping, "species_mapping.csv", row.names = FALSE)
cat("Species mapping saved to species_mapping.csv\n")
}
# Print summary information
cat("\n=== PHYLOSEQ OBJECT SUMMARY ===\n")
print(ps)
cat("\n=== OTU TABLE DIMENSIONS ===\n")
cat("Rows (OTUs/ASVs):", nrow(otu_table_data), "\n")
cat("Columns (Samples):", ncol(otu_table_data), "\n")
cat("\n=== SAMPLE NAMES ===\n")
print(colnames(otu_table_data))
if(exists("species_names")) {
cat("\n=== FIRST 10 SPECIES NAMES ===\n")
print(head(species_names, 10))
}
cat("\n=== FILES CREATED ===\n")
cat("- otu_table_with_species.csv (OTU table with species names)\n")
cat("- otu_table_numeric.csv (OTU table with numeric IDs)\n")
if(exists("species_names")) {
cat("- species_mapping.csv (mapping between numeric IDs and species names)\n")
}
if(!is.null(tax_table(ps))) {
cat("- taxonomy_table.csv (full taxonomy information)\n")
}
} else {
cat("No phyloseq object found in the RDA file.\n")
cat("Available objects:\n")
for(obj_name in ls()) {
cat("-", obj_name, ":", class(get(obj_name))[1], "\n")
}
}
# Extract OTU data from wheat phyloseq RDA file
# Load required libraries
library(phyloseq)
# Set working directory to the project root (adjust if needed)
setwd("c:/MicrobiomeBot/Microbot-")
# Load the RDA file
load("data/BCM_16S_wheat_phyloseq_filtered_lulu.rda")
# Check what objects are loaded
print("Objects loaded from RDA file:")
print(ls())
# The phyloseq object is named BCM_16S_wheat_phyloseq_filtered_lulu
ps <- BCM_16S_wheat_phyloseq_filtered_lulu
# Extract OTU table (abundance data)
otu_table_data <- as.data.frame(otu_table(ps))
# Extract taxonomy table (species names)
if(!is.null(tax_table(ps))) {
taxonomy_data <- as.data.frame(tax_table(ps))
# Create species names from taxonomy with unique identifiers
species_names <- apply(taxonomy_data, 1, function(x) {
# Find the last non-NA taxonomic level
last_level <- tail(x[!is.na(x) & x != ""], 1)
if(length(last_level) > 0) {
return(as.character(last_level))
} else {
return("Unknown")
}
})
# Make species names unique by adding OTU IDs
original_rownames <- rownames(otu_table_data)
unique_species_names <- paste0(species_names, "_", original_rownames)
# Create OTU table with unique species names
otu_with_species <- otu_table_data
rownames(otu_with_species) <- unique_species_names
# Save taxonomy information
write.csv(taxonomy_data, "taxonomy_table.csv", row.names = TRUE)
cat("Taxonomy table saved to taxonomy_table.csv\n")
# Save OTU table with species names
write.csv(otu_with_species, "otu_table_with_species.csv", row.names = TRUE)
# Create a mapping file between numeric IDs and species names
species_mapping <- data.frame(
numeric_id = 0:(length(species_names)-1),
otu_id = original_rownames,
species_name = species_names,
unique_name = unique_species_names,
stringsAsFactors = FALSE
)
write.csv(species_mapping, "species_mapping.csv", row.names = FALSE)
cat("Species mapping saved to species_mapping.csv\n")
}
# Also save a version with numeric IDs (for compatibility with current analysis)
otu_numeric <- otu_table_data
rownames(otu_numeric) <- 0:(nrow(otu_numeric)-1)
write.csv(otu_numeric, "otu_table_numeric.csv", row.names = TRUE)
# Print summary information
cat("\n=== PHYLOSEQ OBJECT SUMMARY ===\n")
print(ps)
cat("\n=== OTU TABLE DIMENSIONS ===\n")
cat("Rows (OTUs/ASVs):", nrow(otu_table_data), "\n")
cat("Columns (Samples):", ncol(otu_table_data), "\n")
cat("\n=== SAMPLE NAMES ===\n")
print(colnames(otu_table_data))
if(exists("species_names")) {
cat("\n=== FIRST 10 SPECIES NAMES ===\n")
print(head(species_names, 10))
cat("\n=== FIRST 10 UNIQUE NAMES ===\n")
print(head(unique_species_names, 10))
}
cat("\n=== FILES CREATED ===\n")
cat("- otu_table_with_species.csv (OTU table with unique species names)\n")
cat("- otu_table_numeric.csv (OTU table with numeric IDs)\n")
cat("- species_mapping.csv (mapping between numeric IDs and species names)\n")
cat("- taxonomy_table.csv (full taxonomy information)\n")
# OTU Data Cleaning Script
# This script cleans sparse microbiome OTU data for faster analysis
# Load required libraries
library(dplyr)
library(readr)
# OTU Data Cleaning Script
# This script cleans sparse microbiome OTU data for faster analysis
# Load required libraries (only dplyr, using base R for file I/O)
library(dplyr)
# Function to clean OTU data
clean_otu_data <- function(input_file = "otu_table_with_species.csv",
output_file = "otu_table_cleaned.csv",
min_prevalence = 0.05,  # Feature must be present in at least 5% of samples
min_abundance = 10,     # Minimum total abundance per feature
max_features = 200,     # Maximum number of features to keep
remove_low_samples = TRUE) {
cat("Loading OTU data from:", input_file, "\n")
# Read the OTU table using base R
otu_data <- read.csv(input_file, row.names = 1, check.names = FALSE)
cat("Original data dimensions:", nrow(otu_data), "features x", ncol(otu_data), "samples\n")
# Calculate sparsity
total_cells <- nrow(otu_data) * ncol(otu_data)
zero_cells <- sum(otu_data == 0)
sparsity <- (zero_cells / total_cells) * 100
cat("Data sparsity:", round(sparsity, 1), "% zeros\n")
# Step 1: Remove features with very low prevalence
min_samples <- max(2, round(ncol(otu_data) * min_prevalence))
feature_prevalence <- rowSums(otu_data > 0)
prevalent_features <- feature_prevalence >= min_samples
cat("Step 1: Removing features present in <", min_samples, "samples\n")
otu_cleaned <- otu_data[prevalent_features, ]
cat("Kept", nrow(otu_cleaned), "features after prevalence filtering\n")
# Step 2: Remove features with very low total abundance
feature_abundance <- rowSums(otu_cleaned)
abundant_features <- feature_abundance >= min_abundance
cat("Step 2: Removing features with total abundance <", min_abundance, "\n")
otu_cleaned <- otu_cleaned[abundant_features, ]
cat("Kept", nrow(otu_cleaned), "features after abundance filtering\n")
# Step 3: Keep only top abundant features if still too many
if (nrow(otu_cleaned) > max_features) {
cat("Step 3: Keeping top", max_features, "most abundant features\n")
feature_totals <- rowSums(otu_cleaned)
top_features <- names(sort(feature_totals, decreasing = TRUE)[1:max_features])
otu_cleaned <- otu_cleaned[top_features, ]
cat("Kept", nrow(otu_cleaned), "top abundant features\n")
}
# Step 4: Remove low-abundance samples (optional)
if (remove_low_samples) {
sample_totals <- colSums(otu_cleaned)
abundance_threshold <- quantile(sample_totals, 0.1)  # Bottom 10%
good_samples <- sample_totals > abundance_threshold
cat("Step 4: Removing samples with abundance <=", round(abundance_threshold), "\n")
otu_cleaned <- otu_cleaned[, good_samples]
cat("Kept", ncol(otu_cleaned), "samples after sample filtering\n")
}
# Step 5: Final cleanup - remove any remaining all-zero rows/columns
otu_cleaned <- otu_cleaned[rowSums(otu_cleaned) > 0, ]
otu_cleaned <- otu_cleaned[, colSums(otu_cleaned) > 0]
# Calculate final sparsity
final_total_cells <- nrow(otu_cleaned) * ncol(otu_cleaned)
final_zero_cells <- sum(otu_cleaned == 0)
final_sparsity <- (final_zero_cells / final_total_cells) * 100
cat("\nFinal cleaned data dimensions:", nrow(otu_cleaned), "features x", ncol(otu_cleaned), "samples\n")
cat("Final sparsity:", round(final_sparsity, 1), "% zeros\n")
cat("Data reduction:", round((1 - (final_total_cells / total_cells)) * 100, 1), "% size reduction\n")
# Save cleaned data using base R
write.csv(otu_cleaned, output_file, row.names = TRUE)
cat("Cleaned data saved to:", output_file, "\n")
# Return summary statistics
return(list(
original_dims = c(nrow(otu_data), ncol(otu_data)),
cleaned_dims = c(nrow(otu_cleaned), ncol(otu_cleaned)),
original_sparsity = sparsity,
cleaned_sparsity = final_sparsity,
size_reduction = (1 - (final_total_cells / total_cells)) * 100
))
}
# Run the cleaning function
cat("=== OTU Data Cleaning Script ===\n")
results <- clean_otu_data()
# OTU Data Cleaning Script
# This script cleans sparse microbiome OTU data for faster analysis
# Set working directory to the correct location
setwd("C:/MicrobiomeBot/Microbot-")
# Load required libraries (only dplyr, using base R for file I/O)
library(dplyr)
# Function to clean OTU data
clean_otu_data <- function(input_file = "otu_table_with_species.csv",
output_file = "otu_table_cleaned.csv",
min_prevalence = 0.05,  # Feature must be present in at least 5% of samples
min_abundance = 10,     # Minimum total abundance per feature
max_features = 200,     # Maximum number of features to keep
remove_low_samples = TRUE) {
cat("Loading OTU data from:", input_file, "\n")
# Read the OTU table using base R
otu_data <- read.csv(input_file, row.names = 1, check.names = FALSE)
cat("Original data dimensions:", nrow(otu_data), "features x", ncol(otu_data), "samples\n")
# Calculate sparsity
total_cells <- nrow(otu_data) * ncol(otu_data)
zero_cells <- sum(otu_data == 0)
sparsity <- (zero_cells / total_cells) * 100
cat("Data sparsity:", round(sparsity, 1), "% zeros\n")
# Step 1: Remove features with very low prevalence
min_samples <- max(2, round(ncol(otu_data) * min_prevalence))
feature_prevalence <- rowSums(otu_data > 0)
prevalent_features <- feature_prevalence >= min_samples
cat("Step 1: Removing features present in <", min_samples, "samples\n")
otu_cleaned <- otu_data[prevalent_features, ]
cat("Kept", nrow(otu_cleaned), "features after prevalence filtering\n")
# Step 2: Remove features with very low total abundance
feature_abundance <- rowSums(otu_cleaned)
abundant_features <- feature_abundance >= min_abundance
cat("Step 2: Removing features with total abundance <", min_abundance, "\n")
otu_cleaned <- otu_cleaned[abundant_features, ]
cat("Kept", nrow(otu_cleaned), "features after abundance filtering\n")
# Step 3: Keep only top abundant features if still too many
if (nrow(otu_cleaned) > max_features) {
cat("Step 3: Keeping top", max_features, "most abundant features\n")
feature_totals <- rowSums(otu_cleaned)
top_features <- names(sort(feature_totals, decreasing = TRUE)[1:max_features])
otu_cleaned <- otu_cleaned[top_features, ]
cat("Kept", nrow(otu_cleaned), "top abundant features\n")
}
# Step 4: Remove low-abundance samples (optional)
if (remove_low_samples) {
sample_totals <- colSums(otu_cleaned)
abundance_threshold <- quantile(sample_totals, 0.1)  # Bottom 10%
good_samples <- sample_totals > abundance_threshold
cat("Step 4: Removing samples with abundance <=", round(abundance_threshold), "\n")
otu_cleaned <- otu_cleaned[, good_samples]
cat("Kept", ncol(otu_cleaned), "samples after sample filtering\n")
}
# Step 5: Final cleanup - remove any remaining all-zero rows/columns
otu_cleaned <- otu_cleaned[rowSums(otu_cleaned) > 0, ]
otu_cleaned <- otu_cleaned[, colSums(otu_cleaned) > 0]
# Calculate final sparsity
final_total_cells <- nrow(otu_cleaned) * ncol(otu_cleaned)
final_zero_cells <- sum(otu_cleaned == 0)
final_sparsity <- (final_zero_cells / final_total_cells) * 100
cat("\nFinal cleaned data dimensions:", nrow(otu_cleaned), "features x", ncol(otu_cleaned), "samples\n")
cat("Final sparsity:", round(final_sparsity, 1), "% zeros\n")
cat("Data reduction:", round((1 - (final_total_cells / total_cells)) * 100, 1), "% size reduction\n")
# Save cleaned data using base R
write.csv(otu_cleaned, output_file, row.names = TRUE)
cat("Cleaned data saved to:", output_file, "\n")
# Return summary statistics
return(list(
original_dims = c(nrow(otu_data), ncol(otu_data)),
cleaned_dims = c(nrow(otu_cleaned), ncol(otu_cleaned)),
original_sparsity = sparsity,
cleaned_sparsity = final_sparsity,
size_reduction = (1 - (final_total_cells / total_cells)) * 100
))
}
# Run the cleaning function
cat("=== OTU Data Cleaning Script ===\n")
results <- clean_otu_data()
cat("\n=== Cleaning Summary ===\n")
cat("Original:", results$original_dims[1], "x", results$original_dims[2], "\n")
cat("Cleaned:", results$cleaned_dims[1], "x", results$cleaned_dims[2], "\n")
cat("Sparsity reduced from", round(results$original_sparsity, 1), "% to", round(results$cleaned_sparsity, 1), "%\n")
cat("Dataset size reduced by", round(results$size_reduction, 1), "%\n")
cat("Cleaning completed successfully!\n")
# R Script to Shorten CSV Files for Microbiome Analysis
# Creates meaningful subsets of large datasets while preserving biological diversity
library(dplyr)
library(readr)
# R Script to Shorten CSV Files for Microbiome Analysis
# Creates meaningful subsets of large datasets while preserving biological diversity
# Using base R functions - no additional packages required
# Function to calculate coefficient of variation for OTU selection
calculate_cv <- function(x) {
if(mean(x, na.rm = TRUE) == 0) return(0)
sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)
}
# 1. SHORTEN INTERACTIONS.CSV (2671 -> 100 rows)
# Strategy: Select top interactions by compression value + diverse interaction types
cat("Processing interactions.csv...\n")
interactions <- read.csv("interactions.csv", stringsAsFactors = FALSE)
# R Script to Shorten CSV Files for Microbiome Analysis
# Creates meaningful subsets of large datasets while preserving biological diversity
# Using base R functions - no additional packages required
# Set working directory
setwd("C:/MicrobiomeBot/Microbot-")
# Function to calculate coefficient of variation for OTU selection
calculate_cv <- function(x) {
if(mean(x, na.rm = TRUE) == 0) return(0)
sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)
}
# 1. SHORTEN INTERACTIONS.CSV (2671 -> 100 rows)
# Strategy: Select top interactions by compression value + diverse interaction types
cat("Processing interactions.csv...\n")
interactions <- read.csv("interactions.csv", stringsAsFactors = FALSE)
# Get top interactions by compression value (most significant)
interactions_ordered <- interactions[order(interactions$comp, decreasing = TRUE), ]
top_by_compression <- interactions_ordered[1:60, ]
# Get diverse interaction types
interaction_types <- unique(interactions$lnk)
diverse_interactions <- data.frame()
for(type in interaction_types) {
type_subset <- interactions[interactions$lnk == type, ]
n_sample <- min(10, nrow(type_subset))
if(n_sample > 0) {
sampled <- type_subset[sample(nrow(type_subset), n_sample), ]
diverse_interactions <- rbind(diverse_interactions, sampled)
}
}
# Take first 40 from diverse interactions
diverse_interactions <- diverse_interactions[1:min(40, nrow(diverse_interactions)), ]
# Combine and ensure exactly 100 rows
interactions_combined <- rbind(top_by_compression, diverse_interactions)
interactions_short <- interactions_combined[!duplicated(interactions_combined), ]
interactions_short <- interactions_short[1:min(100, nrow(interactions_short)), ]
write.csv(interactions_short, "interactions_short.csv", row.names = FALSE)
cat("Created interactions_short.csv with", nrow(interactions_short), "rows\n")
# 2. SHORTEN TAXONOMY_TABLE.CSV (1505 -> 100 rows)
# Strategy: Maximize taxonomic diversity across all levels
cat("Processing taxonomy_table.csv...\n")
taxonomy <- read.csv("taxonomy_table.csv", stringsAsFactors = FALSE)
# Calculate taxonomic diversity score for each OTU
taxonomy$diversity_score <-
(!is.na(taxonomy$Kingdom)) * 1 +
(!is.na(taxonomy$Phylum)) * 2 +
(!is.na(taxonomy$Class)) * 3 +
(!is.na(taxonomy$Order)) * 4 +
(!is.na(taxonomy$Family)) * 5 +
(!is.na(taxonomy$Genus)) * 6
taxonomy_scored <- taxonomy[order(taxonomy$diversity_score, decreasing = TRUE), ]
# Select representatives from each phylum
phylum_list <- unique(taxonomy_scored$Phylum[!is.na(taxonomy_scored$Phylum)])
phylum_representatives <- data.frame()
for(phylum in phylum_list) {
phylum_subset <- taxonomy_scored[!is.na(taxonomy_scored$Phylum) & taxonomy_scored$Phylum == phylum, ]
n_select <- min(5, nrow(phylum_subset))
if(n_select > 0) {
selected <- phylum_subset[1:n_select, ]
phylum_representatives <- rbind(phylum_representatives, selected)
}
}
# Fill remaining slots with high diversity score OTUs
remaining_slots <- 100 - nrow(phylum_representatives)
if(remaining_slots > 0) {
# Get OTUs not already selected
selected_ids <- phylum_representatives[, 1]
remaining_otus <- taxonomy_scored[!(taxonomy_scored[, 1] %in% selected_ids), ]
additional_otus <- remaining_otus[1:min(remaining_slots, nrow(remaining_otus)), ]
taxonomy_short <- rbind(phylum_representatives, additional_otus)
} else {
taxonomy_short <- phylum_representatives[1:100, ]
}
# Remove diversity score column
taxonomy_short$diversity_score <- NULL
write.csv(taxonomy_short, "taxonomy_table_short.csv", row.names = FALSE)
cat("Created taxonomy_table_short.csv with", nrow(taxonomy_short), "rows\n")
# 3. SHORTEN SPECIES_MAPPING.CSV (1505 -> 100 rows)
# Strategy: Match with selected taxonomy OTUs
cat("Processing species_mapping.csv...\n")
species_mapping <- read.csv("species_mapping.csv", stringsAsFactors = FALSE)
# Get OTU IDs from shortened taxonomy
selected_otu_ids <- taxonomy_short[, 1]  # First column contains OTU IDs
# Filter species mapping to match selected OTUs
species_mapping_short <- species_mapping[species_mapping$otu_id %in% selected_otu_ids, ]
species_mapping_short <- species_mapping_short[1:min(100, nrow(species_mapping_short)), ]
write.csv(species_mapping_short, "species_mapping_short.csv", row.names = FALSE)
cat("Created species_mapping_short.csv with", nrow(species_mapping_short), "rows\n")
# 4. SHORTEN OTU_TABLE_NUMERIC.CSV (1505 rows x ~400 cols -> 100x100)
# Strategy: High variance OTUs + representative samples
cat("Processing otu_table_numeric.csv...\n")
otu_numeric <- read.csv("otu_table_numeric.csv", stringsAsFactors = FALSE, check.names = FALSE)
# Calculate variance for each OTU (row)
otu_data <- otu_numeric[, -1]  # Remove first column (OTU names)
otu_variances <- apply(otu_data, 1, function(x) var(as.numeric(x), na.rm = TRUE))
# Select top 100 OTUs by variance (most variable = most informative)
high_var_indices <- order(otu_variances, decreasing = TRUE)[1:min(100, length(otu_variances))]
selected_otus <- otu_numeric[high_var_indices, ]
# Select 100 most diverse samples (columns)
selected_otu_data <- selected_otus[, -1]
sample_sums <- colSums(selected_otu_data, na.rm = TRUE)
# Select samples with good coverage and diversity
sample_indices <- order(sample_sums, decreasing = TRUE)[1:min(100, length(sample_sums))]
sample_names <- names(sample_sums)[sample_indices]
# Create final shortened table
otu_numeric_short <- cbind(selected_otus[, 1, drop = FALSE], selected_otus[, sample_names])
write.csv(otu_numeric_short, "otu_table_numeric_short.csv", row.names = FALSE)
cat("Created otu_table_numeric_short.csv with", nrow(otu_numeric_short), "rows and", ncol(otu_numeric_short)-1, "sample columns\n")
# 5. SHORTEN OTU_TABLE_WITH_SPECIES.CSV (1505 rows x ~400 cols -> 100x100)
# Strategy: Match with selected high-variance OTUs
cat("Processing otu_table_with_species.csv...\n")
otu_species <- read.csv("otu_table_with_species.csv", stringsAsFactors = FALSE, check.names = FALSE)
# Get the row indices that correspond to high variance OTUs
# Match by position since both files should have same OTU order
otu_species_short <- cbind(otu_species[high_var_indices, 1, drop = FALSE],
otu_species[high_var_indices, sample_names])
write.csv(otu_species_short, "otu_table_with_species_short.csv", row.names = FALSE)
cat("Created otu_table_with_species_short.csv with", nrow(otu_species_short), "rows and", ncol(otu_species_short)-1, "sample columns\n")
# 6. CREATE ENHANCED INTERACTIONS (if interactions_enhanced.csv exists)
if(file.exists("interactions_enhanced.csv")) {
cat("Processing interactions_enhanced.csv...\n")
interactions_enhanced <- read.csv("interactions_enhanced.csv", stringsAsFactors = FALSE)
# Match with shortened interactions
if("sp1" %in% names(interactions_enhanced) && "sp2" %in% names(interactions_enhanced)) {
# Create matching logic
match_indices <- c()
for(i in 1:nrow(interactions_enhanced)) {
for(j in 1:nrow(interactions_short)) {
if(interactions_enhanced$sp1[i] == interactions_short$sp1[j] &&
interactions_enhanced$sp2[i] == interactions_short$sp2[j]) {
match_indices <- c(match_indices, i)
break
}
}
}
if(length(match_indices) > 0) {
interactions_enhanced_short <- interactions_enhanced[match_indices, ]
interactions_enhanced_short <- interactions_enhanced_short[1:min(100, nrow(interactions_enhanced_short)), ]
write.csv(interactions_enhanced_short, "interactions_enhanced_short.csv", row.names = FALSE)
cat("Created interactions_enhanced_short.csv with", nrow(interactions_enhanced_short), "rows\n")
}
}
}
# Summary Report
cat("\n=== SHORTENING SUMMARY ===\n")
cat("All files reduced to ~100 rows/columns while preserving:\n")
cat("✓ Interactions: Top compression values + interaction type diversity\n")
cat("✓ Taxonomy: Maximum taxonomic diversity across all levels\n")
cat("✓ Species Mapping: Matched with selected taxonomic OTUs\n")
cat("✓ OTU Tables: High variance OTUs + high coverage samples\n")
cat("✓ Biological meaningfulness maintained through strategic selection\n")
cat("\nFiles created:\n")
cat("- interactions_short.csv\n")
cat("- taxonomy_table_short.csv\n")
cat("- species_mapping_short.csv\n")
cat("- otu_table_numeric_short.csv\n")
cat("- otu_table_with_species_short.csv\n")
if(file.exists("interactions_enhanced.csv")) {
cat("- interactions_enhanced_short.csv\n")
}
cat("\nReady for fast microbiome analysis!\n")
#!/usr/bin/env Rscript
# Usage:
# Rscript make_interact.R --otu path/to/main_otu.csv --outdir ./output
#
# Output: interact.csv (columns: sp1, sp2, lnk, comp)
suppressPackageStartupMessages({
library(optparse)
library(data.table)
library(InfIntE)
})
install.packages("optparse")
install.packages("data.table")
